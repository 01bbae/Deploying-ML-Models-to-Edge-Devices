{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchinfo import summary\n",
    "import timeit\n",
    "import os\n",
    "from prettytable import PrettyTable, SINGLE_BORDER\n",
    "from torch.quantization import prepare, convert, fuse_modules, get_default_qconfig\n",
    "from PIL import Image\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate model compression techniques and export an iOS compatible coreML model to load into mobile devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = 'mps'\n",
    "else:\n",
    "    device_name = 'cpu'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Define the directory for the dataset\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "testing_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader  = DataLoader(training_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "test_data_loader  = DataLoader(testing_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode train\n"
     ]
    }
   ],
   "source": [
    "# Define the directory for the dataset\n",
    "model_dir = \"model\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    mode = 'train'\n",
    "else:\n",
    "    if len(os.listdir(model_dir)) == 0:\n",
    "        mode = 'train'\n",
    "        print(\"no model checkpoints exist\")\n",
    "    else:\n",
    "        mode = 'eval'\n",
    "        print(\"model checkpoints already exist\")\n",
    "\n",
    "# # Mode Override\n",
    "# mode = 'train'\n",
    "print(\"mode\", mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet50 (Modified for CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50SmallPretrained(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet50SmallPretrained, self).__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Method 1: Modify first convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Copy weights from pretrained model with adaptation\n",
    "        with torch.no_grad():\n",
    "            # Adapt the weights by averaging over the original kernel size\n",
    "            original_weights = resnet.conv1.weight\n",
    "            new_weights = torch.mean(original_weights.view(64, 3, 7*7), dim=2).view(64, 3, 1, 1)\n",
    "            self.conv1.weight = nn.Parameter(new_weights)\n",
    "        \n",
    "        # Remove the original first maxpool layer as it's too aggressive for small images\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        \n",
    "        # Keep the rest of the architecture\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        # Adjust the final layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # No maxpool\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = ResNet50SmallPretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet50SmallPretrained                  [128, 10]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 34, 34]         192\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 34, 34]         128\n",
       "├─ReLU: 1-3                              [128, 64, 34, 34]         --\n",
       "├─Sequential: 1-4                        [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 34, 34]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 34, 34]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 34, 34]        16,896\n",
       "│    │    └─ReLU: 3-10                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-11                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-13                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-14                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-16                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-17                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-19                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-20                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-22                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-23                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-25                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-26                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-28                   [128, 256, 34, 34]        --\n",
       "├─Sequential: 1-5                        [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 34, 34]        32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 34, 34]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 512, 17, 17]        1,024\n",
       "│    │    └─Sequential: 3-37             [128, 512, 17, 17]        132,096\n",
       "│    │    └─ReLU: 3-38                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-39                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-41                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-42                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-44                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-45                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-47                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-50                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-53                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-56                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-59                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-62                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-65                   [128, 512, 17, 17]        --\n",
       "├─Sequential: 1-6                        [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 17, 17]        131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 17, 17]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-72                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─Sequential: 3-74             [128, 1024, 9, 9]         526,336\n",
       "│    │    └─ReLU: 3-75                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-81                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-82                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-84                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-85                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-87                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-90                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-102                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-103                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-105                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-106                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-108                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-109                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-111                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-112                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-114                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-115                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-117                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-118                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-120                  [128, 1024, 9, 9]         --\n",
       "├─Sequential: 1-7                        [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-14                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-121                [128, 512, 9, 9]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [128, 512, 9, 9]          1,024\n",
       "│    │    └─ReLU: 3-123                  [128, 512, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-124                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-126                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-127                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─Sequential: 3-129            [128, 2048, 5, 5]         2,101,248\n",
       "│    │    └─ReLU: 3-130                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-15                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-131                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-133                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-134                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-136                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-137                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-139                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-16                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-140                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-142                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-143                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-145                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-146                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-148                  [128, 2048, 5, 5]         --\n",
       "├─AdaptiveAvgPool2d: 1-8                 [128, 2048, 1, 1]         --\n",
       "├─Linear: 1-9                            [128, 10]                 20,490\n",
       "==========================================================================================\n",
       "Total params: 23,519,306\n",
       "Trainable params: 23,519,306\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 208.49\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 8276.68\n",
       "Params size (MB): 94.08\n",
       "Estimated Total Size (MB): 8372.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model_stats = summary(teacher_model, input_size=(batch_size, 3, 32, 32), device=device)\n",
    "teacher_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(teacher_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_training(epochs, data_loader, model, device, optimizer='adam', criterion='ce'):\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than adam\")\n",
    "    if criterion == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than CrossEntropy\")\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(data_loader), 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # send to accelerator\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = running_loss / len(train_data_loader)\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604a40f1d90d48c7bfe9f39cbf2ba253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.5243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd81eb6c839e483da01f27688b16671c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.2787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58cb25590a94b00b0743e21ce4388f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.2262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e6814588b34766bce1f6a860101a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.1940\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b713071772e4476ba0c543dc094eaf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.1701\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    teacher_model = standard_training(epochs, train_data_loader, teacher_model, device)\n",
    "    torch.save(teacher_model, \"model/teacher_model.pt\")\n",
    "else:\n",
    "    torch.load(\"model/teacher_model.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "            \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu1 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # # Remove FloatFunctional and use mul/add ops directly\n",
    "        # self.mul_scalar = torch.ao.quantization.observer.MinMaxObserver()\n",
    "        # Add this for quantized addition\n",
    "        self.add = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Simple addition, will be automatically quantized\n",
    "        out = self.add.add(out, identity)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        \n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.relu1 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.relu2 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu3 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # # Remove FloatFunctional and use mul/add ops directly\n",
    "        # self.mul_scalar = torch.ao.quantization.observer.MinMaxObserver()\n",
    "        # Add this for quantized addition\n",
    "        self.add = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Simple addition, will be automatically quantized\n",
    "        out = self.add.add(out, identity)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet50SmallerStudent(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,  # Changed num_classes to 10\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet50SmallerStudent, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                           \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        # Quantization stubs\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        \n",
    "        # Modified initial conv layer for CIFAR-10\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                              bias=False)  # Changed kernel_size from 7 to 3, stride from 2 to 1\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        # Removed maxpool layer\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                     dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                     dilate=replace_stride_with_dilation[1])\n",
    "        \n",
    "        # Truncate Model to create a smaller model for knowledge distillation\n",
    "        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "        #                              dilate=replace_stride_with_dilation[2])\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)  # Now outputs 10 classes\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                          self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                              base_width=self.base_width, dilation=self.dilation,\n",
    "                              norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # Removed maxpool\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        \"\"\"\n",
    "        Fuse Conv+BN+ReLU layers throughout the model where appropriate.\n",
    "        For BasicBlock and Bottleneck, the final ReLU should not be fused\n",
    "        since it comes after the residual addition.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if type(m) == BasicBlock:\n",
    "                fuse_modules(m, ['conv1', 'bn1', 'relu1'], inplace=True)\n",
    "                fuse_modules(m, ['conv2', 'bn2'], inplace=True)\n",
    "                if m.downsample is not None:\n",
    "                    fuse_modules(m.downsample, ['0', '1'], inplace=True)\n",
    "            elif type(m) == Bottleneck:\n",
    "                fuse_modules(m, ['conv1', 'bn1', 'relu1'], inplace=True)\n",
    "                fuse_modules(m, ['conv2', 'bn2', 'relu2'], inplace=True)\n",
    "                fuse_modules(m, ['conv3', 'bn3'], inplace=True)\n",
    "                if m.downsample is not None:\n",
    "                    fuse_modules(m.downsample, ['0', '1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Student Models\n",
    "# Model is based off of Resnet50 Architecture \n",
    "# One instance without Knowledge Distillation\n",
    "# One instance for Knowledge Distillation\n",
    "# For comparison of effectiveness of KD\n",
    "student_model_noKD = ResNet50SmallerStudent(Bottleneck, [3, 4, 6], num_classes=10).to(device)\n",
    "student_model_KD = ResNet50SmallerStudent(Bottleneck, [3, 4, 6], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet50SmallerStudent                   [128, 10]                 --\n",
       "├─QuantStub: 1-1                         [128, 3, 32, 32]          --\n",
       "├─Conv2d: 1-2                            [128, 64, 32, 32]         1,728\n",
       "├─BatchNorm2d: 1-3                       [128, 64, 32, 32]         128\n",
       "├─ReLU: 1-4                              [128, 64, 32, 32]         --\n",
       "├─Sequential: 1-5                        [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 32, 32]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 32, 32]        16,896\n",
       "│    │    └─FloatFunctional: 3-10        --                        --\n",
       "│    │    └─ReLU: 3-11                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-12                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-13            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-14                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-15                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-16            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-17                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-18                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-19            [128, 256, 32, 32]        512\n",
       "│    │    └─FloatFunctional: 3-20        --                        --\n",
       "│    │    └─ReLU: 3-21                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-22                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-23            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-24                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-25                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-26            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-27                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-28                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-29            [128, 256, 32, 32]        512\n",
       "│    │    └─FloatFunctional: 3-30        --                        --\n",
       "│    │    └─ReLU: 3-31                   [128, 256, 32, 32]        --\n",
       "├─Sequential: 1-6                        [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 32, 32]        32,768\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-37                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-38                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-39            [128, 512, 16, 16]        1,024\n",
       "│    │    └─Sequential: 3-40             [128, 512, 16, 16]        132,096\n",
       "│    │    └─FloatFunctional: 3-41        --                        --\n",
       "│    │    └─ReLU: 3-42                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-43                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-44            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-45                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-46                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-47            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-48                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-49                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-50            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-51        --                        --\n",
       "│    │    └─ReLU: 3-52                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-53                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-54            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-55                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-56                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-57            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-58                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-59                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-60            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-61        --                        --\n",
       "│    │    └─ReLU: 3-62                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-65                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-66                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-68                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-71        --                        --\n",
       "│    │    └─ReLU: 3-72                   [128, 512, 16, 16]        --\n",
       "├─Sequential: 1-7                        [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-73                 [128, 256, 16, 16]        131,072\n",
       "│    │    └─BatchNorm2d: 3-74            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-75                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─Sequential: 3-81             [128, 1024, 8, 8]         526,336\n",
       "│    │    └─FloatFunctional: 3-82        --                        --\n",
       "│    │    └─ReLU: 3-83                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-84                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-85            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-86                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-87                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-88            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-89                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-90                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-91            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-92        --                        --\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-102       --                        --\n",
       "│    │    └─ReLU: 3-103                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-104                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-105           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-106                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-107                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-108           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-109                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-110                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-111           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-112       --                        --\n",
       "│    │    └─ReLU: 3-113                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-114                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-115           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-116                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-117                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-118           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-119                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-120                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-121           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-122       --                        --\n",
       "│    │    └─ReLU: 3-123                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-124                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-125           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-126                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-127                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-128           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-129                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-130                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-131           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-132       --                        --\n",
       "│    │    └─ReLU: 3-133                  [128, 1024, 8, 8]         --\n",
       "├─AdaptiveAvgPool2d: 1-8                 [128, 1024, 1, 1]         --\n",
       "├─Linear: 1-9                            [128, 10]                 10,250\n",
       "├─DeQuantStub: 1-10                      [128, 10]                 --\n",
       "==========================================================================================\n",
       "Total params: 8,545,866\n",
       "Trainable params: 8,545,866\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 132.30\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 6610.23\n",
       "Params size (MB): 34.18\n",
       "Estimated Total Size (MB): 6645.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_stats = summary(student_model_noKD, input_size=(batch_size, 3, 32, 32), device=device)\n",
    "student_model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Student Training (on Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e11b70b4c984f8699d6e179f498821e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 1.4192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91336b7166d34467badb7fd5659737cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.9089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69ba9d54f7d4acb8684d55fc73b06e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.7170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f684a68b2445400e855a4141a5ea6ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.5859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c588b63651480b88346c5e6bc11718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.5180\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    student_model_noKD = standard_training(epochs, train_data_loader, student_model_noKD, device)\n",
    "    torch.save(student_model_noKD, \"model/student_model_noKD.pt\")\n",
    "else:\n",
    "    student_model_noKD = torch.load(\"model/student_model_noKD.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Training from Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code taken from: https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_training(epochs, data_loader, teacher_model, student_model, device, soft_target_loss_weight = 0.25, ce_loss_weight = 0.75, temperature = 2, optimizer='adam', criterion='ce'):\n",
    "    # Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = optim.Adam(student_model.parameters())\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than adam\")\n",
    "    if criterion == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than CrossEntropy\")\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "\n",
    "    # Set teacher model to evaluation mode to not mess with gradients of teacher model\n",
    "    teacher = teacher_model.eval()\n",
    "\n",
    "    student_model.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(data_loader), 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # send to cuda\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            student_logits = student_model(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    teacher_logits = teacher_model(inputs)\n",
    "            \n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by temperature**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (temperature**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = criterion(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = (soft_target_loss_weight * soft_targets_loss) + (ce_loss_weight * label_loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = running_loss / len(train_data_loader)\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "    print('Finished Training')\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2146f017a05943fb8c93db33cc4d1986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 2.0518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178b88bb910c4c9f82aeac04b47cecee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 1.2652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30869f0857b468ba8f6bfe5671e4cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.9371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9e24c08a914b32bc0feb58ac36435e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.7591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc9df6bef504b0ca22f9a008bd7fbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.6511\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    student_model_KD = kd_training(epochs, train_data_loader, teacher_model, student_model_KD, device)\n",
    "    torch.save(student_model_KD, \"model/student_model_KD.pt\")\n",
    "else:\n",
    "    student_model_KD = torch.load(\"model/student_model_KD.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, data_loader, device, testing_mode=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if not testing_mode:\n",
    "        return correct / total\n",
    "        # print(f'Accuracy of {model_name} on the 10000 test images: {100 * correct / total:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ca87f6bc924d6ba0818d565dbdff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538b8f8f59df44a9afc5bfe3445f2d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779e61223d80467bbdb299e9d31fde11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_acc = evaluate_model(teacher_model, \"teacher model\", test_data_loader, device)\n",
    "student_noKD_acc = evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, device)\n",
    "student_KD_acc = evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬──────────┬─────────────────────────┐\n",
      "│         Model         │ Accuracy │ % Decrease from Teacher │\n",
      "├───────────────────────┼──────────┼─────────────────────────┤\n",
      "│     Teacher Model     │ 92.22 %  │            -            │\n",
      "│ Student Model (No KD) │ 82.00 %  │          11.08%         │\n",
      "│   Student Model (KD)  │ 75.23 %  │          18.42%         │\n",
      "└───────────────────────┴──────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_acc_percent = teacher_acc * 100\n",
    "student_noKD_acc_percent = student_noKD_acc * 100\n",
    "student_KD_acc_percent = student_KD_acc * 100\n",
    "\n",
    "teacher_to_student_noKD_acc = ((teacher_acc - student_noKD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "acc_table = PrettyTable()\n",
    "acc_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "acc_table.field_names = [\"Model\", \"Accuracy\", \"% Decrease from Teacher\"]\n",
    "acc_table.add_row([\"Teacher Model\", f\"{teacher_acc_percent:.2f} %\", \"-\"])\n",
    "acc_table.add_row([\"Student Model (No KD)\", f\"{student_noKD_acc_percent:.2f} %\", f\"{teacher_to_student_noKD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model (KD)\", f\"{student_KD_acc_percent:.2f} %\", f\"{teacher_to_student_KD_acc:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Speed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4edcaf7d76a49748e836ca35aee1f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c114f3f57baa4558936b74f75b633e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58143ca87ba64388adea0698aabf4d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af37e86529f24e0c8460bb79db013c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601217a6b4564b499858b3f7d73dd374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1f6f2848224bcc83276463c8dab0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bcfa35c5e14166990dfe7620ef1253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7ccff3161a47869a8ecb0d3c26d257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb0ebb60f274fc19cc8bc5a10000ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7e33745dc344f48fe5ad3ec4441234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05d69d5b0fd47c298d2c178468c758c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9685f1eaeec4cb197852b302a9765ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98424b43ce4c4342a60a99da98a83cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f67f67532a54684ab1cbca23b2d8fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043dc5afd9154a1daba4839a50f4b812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_teacher = timeit.timeit(lambda: evaluate_model(teacher_model, \"teacher model\", test_data_loader, device, testing_mode=True), number=num_runs)\n",
    "time_student_noKD = timeit.timeit(lambda: evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, device, testing_mode=True), number=num_runs)\n",
    "time_student_KD = timeit.timeit(lambda: evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, device, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬──────────────────────────┬─────────────────────────────────────┬─────────────────────────┐\n",
      "│         Model         │ Device Used to Inference │ Time Averaged over 5 runs (seconds) │ % Decrease from Teacher │\n",
      "├───────────────────────┼──────────────────────────┼─────────────────────────────────────┼─────────────────────────┤\n",
      "│     Teacher Model     │           cuda           │                20.32                │            -            │\n",
      "│ Student Model (No KD) │           cuda           │                13.71                │          32.52%         │\n",
      "│   Student Model (KD)  │           cuda           │                13.69                │          32.60%         │\n",
      "└───────────────────────┴──────────────────────────┴─────────────────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_to_student_noKD_time = ((time_teacher - time_student_noKD) / time_teacher) * 100\n",
    "teacher_to_student_KD_time = ((time_teacher - time_student_KD) / time_teacher) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "speed_table = PrettyTable()\n",
    "speed_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "speed_table.field_names = [\"Model\", \"Device Used to Inference\",f\"Time Averaged over {num_runs} runs (seconds)\", \"% Decrease from Teacher\"]\n",
    "speed_table.add_row([\"Teacher Model\", f\"{device}\", f\"{time_teacher:.2f}\", \"-\"])\n",
    "speed_table.add_row([\"Student Model (No KD)\", f\"{device}\", f\"{time_student_noKD:.2f}\", f\"{teacher_to_student_noKD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model (KD)\", f\"{device}\", f\"{time_student_KD:.2f}\", f\"{teacher_to_student_KD_time:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(speed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬─────────────────┬─────────────────────────┐\n",
      "│     Model     │ Model Size (MB) │ % Decrease from Teacher │\n",
      "├───────────────┼─────────────────┼─────────────────────────┤\n",
      "│ Teacher Model │      94.42      │            -            │\n",
      "│ Student Model │      34.43      │          63.54%         │\n",
      "└───────────────┴─────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_model_size = os.path.getsize(\"model/teacher_model.pt\") / 1e6\n",
    "student_model_size = os.path.getsize(\"model/student_model_KD.pt\") / 1e6\n",
    "teacher_to_student_model_size = (teacher_model_size - student_model_size) * 100 / teacher_model_size\n",
    "\n",
    "# Create a PrettyTable object\n",
    "size_table = PrettyTable()\n",
    "size_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "size_table.field_names = [\"Model\", f\"Model Size (MB)\", \"% Decrease from Teacher\"]\n",
    "size_table.add_row([\"Teacher Model\", f\"{teacher_model_size:.2f}\", \"-\"])\n",
    "size_table.add_row([\"Student Model\", f\"{student_model_size:.2f}\", f\"{teacher_to_student_model_size:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(size_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge distilled smaller model is faster than all the models and more accurate than the non knowledge distilled smaller model that was trained regularly using the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing and Exporting KD Model into Mobile Friendly package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Pytorch docs for setup from: https://pytorch.org/executorch/stable/getting-started-setup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization Docs: https://pytorch.org/docs/stable/quantization.html#introduction-to-quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Post Training Static Quantization (PTSQ) from pytorch. There more information of different types of quantization are provided in the quantization docs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take a copy of the Student model with knowledge distillation and move it to a new variable containing the copy of the model to run quantization on\n",
    "student_model_KD_quant_copy = copy.deepcopy(student_model_KD)\n",
    "\n",
    "# Quantization isn't implemented on accelerators so move model back to cpu\n",
    "student_model_KD_quant_copy.to('cpu')\n",
    "\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "student_model_KD_quant_copy.eval()\n",
    "\n",
    "# attach a global qconfig, which contains information about what kind\n",
    "# of observers to attach. Use 'x86' for server inference and 'qnnpack'\n",
    "# for mobile inference. Other quantization configurations such as selecting\n",
    "# symmetric or asymmetric quantization and MinMax or L2Norm calibration techniques\n",
    "# can be specified here.\n",
    "# Note: the old 'fbgemm' is still available but 'x86' is the recommended default\n",
    "# for server inference.\n",
    "# model_fp32.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "student_model_KD_quant_copy.qconfig = get_default_qconfig('qnnpack')\n",
    "\n",
    "# Fuse the activations to preceding layers, where applicable.\n",
    "# This needs to be done manually depending on the model architecture.\n",
    "# Common fusions include `conv + relu` and `conv + batchnorm + relu`\n",
    "student_model_KD_quant_copy.fuse_model()\n",
    "\n",
    "# Prepare the model for static quantization. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "student_model_KD_prepared = prepare(student_model_KD_quant_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.3150,  -6.0617,  11.7452,  ...,  -2.4757,  -6.5796,  -6.8057],\n",
       "        [ -2.9913,  -5.3389,   8.4006,  ...,   1.0409,  -1.5811,  -2.9149],\n",
       "        [ -5.6191, -12.6936,   4.8705,  ...,  19.1144, -11.5949,  -9.0764],\n",
       "        ...,\n",
       "        [ -1.9792,  -1.7147,   6.1368,  ...,   1.6464,  -2.8916,  -3.6043],\n",
       "        [ -8.1207, -10.8889,   4.3876,  ...,   7.9950,  -6.7257,  -8.8520],\n",
       "        [ -2.0201,  -5.0380,   3.3313,  ...,   9.9101,  -5.1875,  -5.0832]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a batch of images for calibration\n",
    "input, _ = next(iter(train_data_loader))\n",
    "\n",
    "# Run the calibration with real data\n",
    "student_model_KD_prepared(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, and replaces key operators with quantized\n",
    "# implementations.\n",
    "student_model_KD_int8 = convert(student_model_KD_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/69426\n",
    "# Can't load regular model saving method so only save weights to load\n",
    "if mode == 'train':\n",
    "    torch.save(student_model_KD_int8, \"model/student_model_KD_int8.pt\") # save full model just to compare model size\n",
    "    torch.save(student_model_KD_int8.state_dict(), \"model/student_model_KD_int8_state_dict.pt\") # use state_dict for actual model loading\n",
    "else:\n",
    "    # Load Model\n",
    "    student_model_KD_int8.load_state_dict(torch.load(\"model/student_model_KD_int8_state_dict.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much size we saved from our previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────┬─────────────────┬─────────────────────────┐\n",
      "│              Model              │ Model Size (MB) │ % Decrease from Teacher │\n",
      "├─────────────────────────────────┼─────────────────┼─────────────────────────┤\n",
      "│          Teacher Model          │      94.42      │            -            │\n",
      "│          Student Model          │      34.43      │          63.54%         │\n",
      "│ Pytorch Quantized Student Model │       8.64      │          90.85%         │\n",
      "└─────────────────────────────────┴─────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_model_size = os.path.getsize(\"model/teacher_model.pt\") / 1e6\n",
    "student_model_size = os.path.getsize(\"model/student_model_KD.pt\") / 1e6\n",
    "student_model_pytorch_quantized_size = os.path.getsize(\"model/student_model_KD_int8.pt\") / 1e6\n",
    "\n",
    "teacher_to_student_model_size = (teacher_model_size - student_model_size) * 100 / teacher_model_size\n",
    "teacher_to_pytorch_quantized_student_model_size = (teacher_model_size - student_model_pytorch_quantized_size) * 100 / teacher_model_size\n",
    "\n",
    "# Create a PrettyTable object\n",
    "size_table = PrettyTable()\n",
    "size_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "size_table.field_names = [\"Model\", f\"Model Size (MB)\", \"% Decrease from Teacher\"]\n",
    "size_table.add_row([\"Teacher Model\", f\"{teacher_model_size:.2f}\", \"-\"])\n",
    "size_table.add_row([\"Student Model\", f\"{student_model_size:.2f}\", f\"{teacher_to_student_model_size:.2f}%\"])\n",
    "size_table.add_row([\"Pytorch Quantized Student Model\", f\"{student_model_pytorch_quantized_size:.2f}\", f\"{teacher_to_pytorch_quantized_student_model_size:.2f}%\"])\n",
    "\n",
    "\n",
    "# Print the table\n",
    "print(size_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see almost a 90% reduction in model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0c9c47a90244a69b9ed4dda2f90973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student_KD_pytorch_quant_acc = evaluate_model(student_model_KD_int8, \"Pytorch quantized student model\", test_data_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────┬──────────┬─────────────────────────┐\n",
      "│               Model               │ Accuracy │ % Decrease from Teacher │\n",
      "├───────────────────────────────────┼──────────┼─────────────────────────┤\n",
      "│           Teacher Model           │ 92.22 %  │            -            │\n",
      "│       Student Model (No KD)       │ 82.00 %  │          11.08%         │\n",
      "│         Student Model (KD)        │ 75.23 %  │          18.42%         │\n",
      "│ Student Model Quantized Int8 (KD) │ 75.23 %  │          18.42%         │\n",
      "└───────────────────────────────────┴──────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_acc_percent = teacher_acc * 100\n",
    "student_noKD_acc_percent = student_noKD_acc * 100\n",
    "student_KD_acc_percent = student_KD_acc * 100\n",
    "student_KD_pytorch_quant_acc_percent = student_KD_pytorch_quant_acc * 100\n",
    "\n",
    "\n",
    "teacher_to_student_noKD_acc = ((teacher_acc - student_noKD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_pytorch_quant_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "acc_table = PrettyTable()\n",
    "acc_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "acc_table.field_names = [\"Model\", \"Accuracy\", \"% Decrease from Teacher\"]\n",
    "acc_table.add_row([\"Teacher Model\", f\"{teacher_acc_percent:.2f} %\", \"-\"])\n",
    "acc_table.add_row([\"Student Model (No KD)\", f\"{student_noKD_acc_percent:.2f} %\", f\"{teacher_to_student_noKD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model (KD)\", f\"{student_KD_acc_percent:.2f} %\", f\"{teacher_to_student_KD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model Quantized Int8 (KD)\", f\"{student_KD_pytorch_quant_acc_percent:.2f} %\", f\"{teacher_to_student_KD_pytorch_quant_acc:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bc069bf2934a96975215a4ab064a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4091e3c964364c7ca39ca323efc614a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1491f25436bb41cc93310745f71f32b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8e25e65cfe4f06b0de41c8cca95eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac1e93bc334b0f98428335d8d325b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19052c4b1b9943a683fac354f96d401c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe5726ce0d470b89af70b5731b9d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02582749ed8e4610a359ae4d58311e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251e5857eed44fbd96d1cebdb15de3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b74ea32414acbba37395d11b7477d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f610e5c9344f4143be2b7451b64892ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a67532cff5d4e6e8832c9fc791f56e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0582393756940d8a8a2ed4ee85eaef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf511839f084d8e81f51958e930e4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce46601b94de4acc9e3dea5a94b7dbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6767fef876b1456dbc9694116b3b0a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a5b476175147a7afebc0a46509289f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5584e831f8b14318bc201fe28ad96330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2110384ab293424ea0aa71da06dae9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df63c89e76d4f27a5f451b9737699e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_teacher_cpu = timeit.timeit(lambda: evaluate_model(teacher_model, \"teacher model\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)\n",
    "time_student_noKD_cpu = timeit.timeit(lambda: evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)\n",
    "time_student_KD_cpu = timeit.timeit(lambda: evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)\n",
    "time_student_pytorch_quantized_cpu = timeit.timeit(lambda: evaluate_model(student_model_KD_int8, \"Pytorch quantized student model\", test_data_loader,\"cpu\", testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────┬──────────────────────────┬─────────────────────────────────────┬─────────────────────────┐\n",
      "│            Model             │ Device used to inference │ Time Averaged over 5 runs (seconds) │ % Decrease from Teacher │\n",
      "├──────────────────────────────┼──────────────────────────┼─────────────────────────────────────┼─────────────────────────┤\n",
      "│        Teacher Model         │           CPU            │                942.96               │            -            │\n",
      "│    Student Model (No KD)     │           CPU            │                651.03               │          30.96%         │\n",
      "│      Student Model (KD)      │           CPU            │                668.84               │          29.07%         │\n",
      "│ Student Model Quantized (KD) │           CPU            │                598.93               │          36.48%         │\n",
      "└──────────────────────────────┴──────────────────────────┴─────────────────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_to_student_noKD_time = ((time_teacher_cpu - time_student_noKD_cpu) / time_teacher_cpu) * 100\n",
    "teacher_to_student_KD_time = ((time_teacher_cpu - time_student_KD_cpu) / time_teacher_cpu) * 100\n",
    "teacher_to_student_pytorch_quantized_time = ((time_teacher_cpu - time_student_pytorch_quantized_cpu) / time_teacher_cpu) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "speed_table = PrettyTable()\n",
    "speed_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "speed_table.field_names = [\"Model\", \"Device used to inference\", f\"Time Averaged over {num_runs} runs (seconds)\", \"% Decrease from Teacher\"]\n",
    "speed_table.add_row([\"Teacher Model\", \"CPU\", f\"{time_teacher_cpu:.2f}\", \"-\"])\n",
    "speed_table.add_row([\"Student Model (No KD)\", \"CPU\", f\"{time_student_noKD_cpu:.2f}\", f\"{teacher_to_student_noKD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model (KD)\", \"CPU\", f\"{time_student_KD_cpu:.2f}\", f\"{teacher_to_student_KD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model Quantized (KD)\", \"CPU\", f\"{time_student_pytorch_quantized_cpu:.2f}\", f\"{teacher_to_student_pytorch_quantized_time:.2f}%\"])\n",
    "\n",
    "\n",
    "# Print the table\n",
    "print(speed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Quantized model is slightly slower than the Original Student model with KD but this might be due to hardware differences as the quantized model is optimized for edge and mobile devices and the original model being optimized for CPU/GPU hardware and this test was done on an x86 CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting as CoreML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after training the above quantized model, it seems to be that CoreML tools from Apple do not support fusing layers and Batch Norm 2d Quantized from Pytorch. To quantize the model it seems that we should be using coreML's own optimize functions to quantize our model for compatibility. While the selection of quantization techinques are similar, they are done in a slightly different manner. The CoreML implementation of PTSQ does not calibrate activations from a representative sample dataset. Since coreML is the library that the apple hardware is optimized for, we will use this library instead and remake the Knowledge Distilled Model without fusing layers.\n",
    "\n",
    "Note that the above model still should work for other mobile and edge platforms as a quantized model, but this will be hardware dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model should be the same overall architecture of KD student model with quantization, without fused layers.\n",
    "\n",
    "We are still using PTSQ (documentation for coreML [here](https://apple.github.io/coremltools/source/coremltools.optimize.torch.quantization.html#coremltools.optimize.torch.quantization.PostTrainingQuantizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch version 2.5.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.4.0 is the most recent version that has been tested.\n",
      "Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.optimize.torch.quantization import (\n",
    "    PostTrainingQuantizerConfig,\n",
    "    PostTrainingQuantizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_KD_quant_copy_coreml = copy.deepcopy(student_model_KD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50SmallerStudent(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_KD_quant_copy_coreml.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the quantizer\n",
    "config = PostTrainingQuantizerConfig.from_dict(\n",
    "    {\n",
    "        \"global_config\": {\n",
    "            \"weight_dtype\": \"int8\",\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptq = PostTrainingQuantizer(student_model_KD_quant_copy_coreml, config)\n",
    "quantized_model_coreml = ptq.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the model with random data.\n",
    "example_input = torch.rand(1, 3, 32, 32) \n",
    "traced_model = torch.jit.trace(quantized_model_coreml, example_input)\n",
    "out = traced_model(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 349/350 [00:00<00:00, 5166.53 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 226.17 passes/s]\n",
      "Running MIL default pipeline:   0%|          | 0/88 [00:00<?, ? passes/s]/home/bbae/miniconda3/envs/edge/lib/python3.11/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:245: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 88/88 [00:00<00:00, 121.23 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 228.59 passes/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input tensor that matches the input shape expected by your model\n",
    "dummy_input = torch.randn(1, 3, 32, 32)  # Adjust based on your input size (e.g., CIFAR-10 images)\n",
    "\n",
    "traced_model.eval()\n",
    "\n",
    "# Convert the quantized PyTorch model to Core ML directly\n",
    "core_ml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)],\n",
    "    minimum_deployment_target=ct.target.iOS17\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_ml_model.save(\"core_ml_model_quantized.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics should be relatively the same as pytorch implementation of quantization maybe slightly worse accuracy due to no calibration of activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save sample images from Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cifar10_samples(num_samples=10, output_dir='cifar10_samples', random_seed=None):\n",
    "    \"\"\"\n",
    "    Load random samples from CIFAR-10 dataset and save them as PNG files\n",
    "    \n",
    "    Args:\n",
    "        num_samples (int): Number of samples to save\n",
    "        output_dir (str): Directory to save the images\n",
    "        random_seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        list: List of saved file paths and their corresponding labels\n",
    "    \"\"\"\n",
    "    # Set random seed if provided\n",
    "    if random_seed is not None:\n",
    "        torch.manual_seed(random_seed)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define the transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Load CIFAR-10 training dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True,\n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Get random indices\n",
    "    indices = torch.randperm(len(trainset))[:num_samples]\n",
    "    \n",
    "    # CIFAR-10 classes\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    # Save each sample\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get image and label\n",
    "        image, label = trainset[idx]\n",
    "        \n",
    "        # Convert from torch tensor to numpy array\n",
    "        img_np = image.numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Scale to [0, 255] and convert to uint8\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img_pil = Image.fromarray(img_np)\n",
    "        \n",
    "        # Create filename with index, class name and original index\n",
    "        filename = f\"{i:02d}_{classes[label]}_{idx}.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Save image\n",
    "        img_pil.save(filepath)\n",
    "        \n",
    "        saved_files.append({\n",
    "            'filepath': filepath,\n",
    "            'class': classes[label],\n",
    "            'original_index': idx.item()\n",
    "        })\n",
    "        \n",
    "        print(f\"Saved {filepath}\")\n",
    "    \n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_saved_samples(saved_files):\n",
    "    \"\"\"\n",
    "    Display the saved CIFAR-10 samples in a grid\n",
    "    \n",
    "    Args:\n",
    "        saved_files (list): List of dictionaries containing file information\n",
    "    \"\"\"\n",
    "    num_samples = len(saved_files)\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(2*num_samples, 2))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, file_info in enumerate(saved_files):\n",
    "        # Load and display image\n",
    "        img = Image.open(file_info['filepath'])\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{file_info['class']}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Saved cifar10_samples/00_frog_37542.png\n",
      "Saved cifar10_samples/01_bird_44491.png\n",
      "Saved cifar10_samples/02_ship_216.png\n",
      "Saved cifar10_samples/03_frog_43688.png\n",
      "Saved cifar10_samples/04_frog_41558.png\n",
      "Saved cifar10_samples/05_truck_32245.png\n",
      "Saved cifar10_samples/06_deer_27206.png\n",
      "Saved cifar10_samples/07_dog_10863.png\n",
      "Saved cifar10_samples/08_deer_2190.png\n",
      "Saved cifar10_samples/09_deer_31849.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save 10 random samples\n",
    "saved_files = save_cifar10_samples(\n",
    "    num_samples=10,\n",
    "    output_dir='cifar10_samples',\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Display the saved samples\n",
    "display_saved_samples(saved_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
