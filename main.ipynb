{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torchinfo import summary\n",
    "import timeit\n",
    "import os\n",
    "from prettytable import PrettyTable, SINGLE_BORDER\n",
    "from torch.quantization import prepare, convert, fuse_modules, get_default_qconfig\n",
    "from torch.ao.nn.intrinsic.modules.fused import ConvReLU2d\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate model compression techniques and export an iOS compatible coreML model to load into mobile devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_name = 'mps'\n",
    "else:\n",
    "    device_name = 'cpu'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Define the directory for the dataset\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "testing_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader  = torch.utils.data.DataLoader(training_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "test_data_loader  = torch.utils.data.DataLoader(testing_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode train\n"
     ]
    }
   ],
   "source": [
    "# Define the directory for the dataset\n",
    "model_dir = \"model\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    mode = 'train'\n",
    "else:\n",
    "    if len(os.listdir(model_dir)) == 0:\n",
    "        mode = 'train'\n",
    "        print(\"no model checkpoints exist\")\n",
    "    else:\n",
    "        mode = 'eval'\n",
    "        print(\"model checkpoints already exist\")\n",
    "print(\"mode\", mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet50 (Modified for CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50SmallPretrained(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet50SmallPretrained, self).__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Method 1: Modify first convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Copy weights from pretrained model with adaptation\n",
    "        with torch.no_grad():\n",
    "            # Adapt the weights by averaging over the original kernel size\n",
    "            original_weights = resnet.conv1.weight\n",
    "            new_weights = torch.mean(original_weights.view(64, 3, 7*7), dim=2).view(64, 3, 1, 1)\n",
    "            self.conv1.weight = nn.Parameter(new_weights)\n",
    "        \n",
    "        # Remove the original first maxpool layer as it's too aggressive for small images\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        \n",
    "        # Keep the rest of the architecture\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        # Adjust the final layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # No maxpool\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = ResNet50SmallPretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet50SmallPretrained                  [128, 10]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 34, 34]         192\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 34, 34]         128\n",
       "├─ReLU: 1-3                              [128, 64, 34, 34]         --\n",
       "├─Sequential: 1-4                        [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 34, 34]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 34, 34]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 34, 34]        16,896\n",
       "│    │    └─ReLU: 3-10                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-11                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-13                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-14                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-16                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-17                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-19                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-20                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-22                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-23                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-25                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-26                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-28                   [128, 256, 34, 34]        --\n",
       "├─Sequential: 1-5                        [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 34, 34]        32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 34, 34]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 512, 17, 17]        1,024\n",
       "│    │    └─Sequential: 3-37             [128, 512, 17, 17]        132,096\n",
       "│    │    └─ReLU: 3-38                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-39                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-41                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-42                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-44                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-45                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-47                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-50                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-53                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-56                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-59                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-62                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-65                   [128, 512, 17, 17]        --\n",
       "├─Sequential: 1-6                        [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 17, 17]        131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 17, 17]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-72                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─Sequential: 3-74             [128, 1024, 9, 9]         526,336\n",
       "│    │    └─ReLU: 3-75                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-81                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-82                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-84                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-85                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-87                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-90                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-102                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-103                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-105                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-106                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-108                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-109                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-111                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-112                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-114                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-115                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-117                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-118                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-120                  [128, 1024, 9, 9]         --\n",
       "├─Sequential: 1-7                        [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-14                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-121                [128, 512, 9, 9]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [128, 512, 9, 9]          1,024\n",
       "│    │    └─ReLU: 3-123                  [128, 512, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-124                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-126                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-127                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─Sequential: 3-129            [128, 2048, 5, 5]         2,101,248\n",
       "│    │    └─ReLU: 3-130                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-15                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-131                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-133                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-134                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-136                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-137                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-139                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-16                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-140                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-142                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-143                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-145                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-146                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-148                  [128, 2048, 5, 5]         --\n",
       "├─AdaptiveAvgPool2d: 1-8                 [128, 2048, 1, 1]         --\n",
       "├─Linear: 1-9                            [128, 10]                 20,490\n",
       "==========================================================================================\n",
       "Total params: 23,519,306\n",
       "Trainable params: 23,519,306\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 208.49\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 8276.68\n",
       "Params size (MB): 94.08\n",
       "Estimated Total Size (MB): 8372.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model_stats = summary(teacher_model, input_size=(batch_size, 3, 32, 32), device=device)\n",
    "teacher_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(teacher_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_training(epochs, data_loader, model, device, optimizer='adam', criterion='ce'):\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than adam\")\n",
    "    if criterion == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than CrossEntropy\")\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(data_loader), 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # send to accelerator\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = running_loss / len(train_data_loader)\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f574ba1092f4f43bbd0773a76efcaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.5150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65492b49b3ba49b59526c69b4d90afa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.2822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081366ef142d41338edf9a70c739a795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.2225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9809ab387f34651a6c80e4f9e6091d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.1940\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f795bcade7465faa259d62eae91e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.1681\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    teacher_model = standard_training(epochs, train_data_loader, teacher_model, device)\n",
    "    torch.save(teacher_model, \"model/teacher_model.pt\")\n",
    "else:\n",
    "    torch.load(\"model/teacher_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "            \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu1 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # # Remove FloatFunctional and use mul/add ops directly\n",
    "        # self.mul_scalar = torch.ao.quantization.observer.MinMaxObserver()\n",
    "        # Add this for quantized addition\n",
    "        self.add = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Simple addition, will be automatically quantized\n",
    "        out = self.add.add(out, identity)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        \n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.relu1 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.relu2 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu3 = nn.ReLU(inplace=False)  # Changed to non-inplace\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # # Remove FloatFunctional and use mul/add ops directly\n",
    "        # self.mul_scalar = torch.ao.quantization.observer.MinMaxObserver()\n",
    "        # Add this for quantized addition\n",
    "        self.add = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Simple addition, will be automatically quantized\n",
    "        out = self.add.add(out, identity)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,  # Changed num_classes to 10\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                           \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        # Quantization stubs\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        \n",
    "        # Modified initial conv layer for CIFAR-10\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                              bias=False)  # Changed kernel_size from 7 to 3, stride from 2 to 1\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        # Removed maxpool layer\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                     dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                     dilate=replace_stride_with_dilation[1])\n",
    "        \n",
    "        # Truncate Model to create a smaller model for knowledge distillation\n",
    "        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "        #                              dilate=replace_stride_with_dilation[2])\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)  # Now outputs 10 classes\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                          self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                              base_width=self.base_width, dilation=self.dilation,\n",
    "                              norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # Removed maxpool\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        \"\"\"\n",
    "        Fuse Conv+BN+ReLU layers throughout the model where appropriate.\n",
    "        For BasicBlock and Bottleneck, the final ReLU should not be fused\n",
    "        since it comes after the residual addition.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if type(m) == BasicBlock:\n",
    "                torch.ao.quantization.fuse_modules(m, ['conv1', 'bn1', 'relu1'], inplace=True)\n",
    "                torch.ao.quantization.fuse_modules(m, ['conv2', 'bn2'], inplace=True)\n",
    "                if m.downsample is not None:\n",
    "                    torch.ao.quantization.fuse_modules(m.downsample, ['0', '1'], inplace=True)\n",
    "            elif type(m) == Bottleneck:\n",
    "                torch.ao.quantization.fuse_modules(m, ['conv1', 'bn1', 'relu1'], inplace=True)\n",
    "                torch.ao.quantization.fuse_modules(m, ['conv2', 'bn2', 'relu2'], inplace=True)\n",
    "                torch.ao.quantization.fuse_modules(m, ['conv3', 'bn3'], inplace=True)\n",
    "                if m.downsample is not None:\n",
    "                    torch.ao.quantization.fuse_modules(m.downsample, ['0', '1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Student Models\n",
    "# Model is based off of Resnet34 Architecture \n",
    "# One instance without Knowledge Distillation\n",
    "# One instance for Knowledge Distillation\n",
    "# For comparison of effectiveness of KD\n",
    "student_model_noKD = ResNet(Bottleneck, [3, 4, 6], num_classes=10).to(device)\n",
    "student_model_KD = ResNet(Bottleneck, [3, 4, 6], num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [128, 10]                 --\n",
       "├─QuantStub: 1-1                         [128, 3, 32, 32]          --\n",
       "├─Conv2d: 1-2                            [128, 64, 32, 32]         1,728\n",
       "├─BatchNorm2d: 1-3                       [128, 64, 32, 32]         128\n",
       "├─ReLU: 1-4                              [128, 64, 32, 32]         --\n",
       "├─Sequential: 1-5                        [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 32, 32]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 32, 32]        16,896\n",
       "│    │    └─FloatFunctional: 3-10        --                        --\n",
       "│    │    └─ReLU: 3-11                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-12                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-13            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-14                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-15                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-16            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-17                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-18                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-19            [128, 256, 32, 32]        512\n",
       "│    │    └─FloatFunctional: 3-20        --                        --\n",
       "│    │    └─ReLU: 3-21                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-22                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-23            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-24                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-25                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-26            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-27                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-28                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-29            [128, 256, 32, 32]        512\n",
       "│    │    └─FloatFunctional: 3-30        --                        --\n",
       "│    │    └─ReLU: 3-31                   [128, 256, 32, 32]        --\n",
       "├─Sequential: 1-6                        [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 32, 32]        32,768\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-37                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-38                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-39            [128, 512, 16, 16]        1,024\n",
       "│    │    └─Sequential: 3-40             [128, 512, 16, 16]        132,096\n",
       "│    │    └─FloatFunctional: 3-41        --                        --\n",
       "│    │    └─ReLU: 3-42                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-43                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-44            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-45                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-46                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-47            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-48                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-49                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-50            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-51        --                        --\n",
       "│    │    └─ReLU: 3-52                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-53                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-54            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-55                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-56                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-57            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-58                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-59                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-60            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-61        --                        --\n",
       "│    │    └─ReLU: 3-62                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-65                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-66                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-68                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 512, 16, 16]        1,024\n",
       "│    │    └─FloatFunctional: 3-71        --                        --\n",
       "│    │    └─ReLU: 3-72                   [128, 512, 16, 16]        --\n",
       "├─Sequential: 1-7                        [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-73                 [128, 256, 16, 16]        131,072\n",
       "│    │    └─BatchNorm2d: 3-74            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-75                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─Sequential: 3-81             [128, 1024, 8, 8]         526,336\n",
       "│    │    └─FloatFunctional: 3-82        --                        --\n",
       "│    │    └─ReLU: 3-83                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-84                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-85            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-86                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-87                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-88            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-89                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-90                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-91            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-92        --                        --\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-102       --                        --\n",
       "│    │    └─ReLU: 3-103                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-104                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-105           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-106                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-107                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-108           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-109                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-110                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-111           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-112       --                        --\n",
       "│    │    └─ReLU: 3-113                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-114                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-115           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-116                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-117                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-118           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-119                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-120                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-121           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-122       --                        --\n",
       "│    │    └─ReLU: 3-123                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-124                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-125           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-126                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-127                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-128           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-129                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-130                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-131           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─FloatFunctional: 3-132       --                        --\n",
       "│    │    └─ReLU: 3-133                  [128, 1024, 8, 8]         --\n",
       "├─AdaptiveAvgPool2d: 1-8                 [128, 1024, 1, 1]         --\n",
       "├─Linear: 1-9                            [128, 10]                 10,250\n",
       "├─DeQuantStub: 1-10                      [128, 10]                 --\n",
       "==========================================================================================\n",
       "Total params: 8,545,866\n",
       "Trainable params: 8,545,866\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 132.30\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 6610.23\n",
       "Params size (MB): 34.18\n",
       "Estimated Total Size (MB): 6645.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_stats = summary(student_model_noKD, input_size=(batch_size, 3, 32, 32), device=device)\n",
    "student_model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Student Training (on Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39150ed73cb84152b4ad36cc46d0b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 1.4377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97971b3b3a8343a488f41f05f1d1cc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.9130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e787f4a89c0c4d26a265385704d4f7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.7012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ea5a0c31fd4807b5fd0419514c1f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.5892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddeee1a4b74450fbdb4278b65ac51ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.5125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    student_model_noKD = standard_training(epochs, train_data_loader, student_model_noKD, device)\n",
    "    torch.save(student_model_noKD, \"model/student_model_noKD.pt\")\n",
    "else:\n",
    "    student_model_noKD = torch.load(\"model/student_model_noKD.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Training from Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code taken from: https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_training(epochs, data_loader, teacher_model, student_model, device, soft_target_loss_weight = 0.25, ce_loss_weight = 0.75, temperature = 2, optimizer='adam', criterion='ce'):\n",
    "    # Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = optim.Adam(student_model.parameters())\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than adam\")\n",
    "    if criterion == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"optimizer string matcher is not implemented yet other than CrossEntropy\")\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "\n",
    "    # Set teacher model to evaluation mode to not mess with gradients of teacher model\n",
    "    teacher = teacher_model.eval()\n",
    "\n",
    "    student_model.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(data_loader), 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # send to cuda\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            student_logits = student_model(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    teacher_logits = teacher_model(inputs)\n",
    "            \n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by temperature**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (temperature**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = criterion(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = (soft_target_loss_weight * soft_targets_loss) + (ce_loss_weight * label_loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = running_loss / len(train_data_loader)\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "    print('Finished Training')\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418179a582fd4a74bea1ffdad307a958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 2.0583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde8732a232f405d80fe505f43b48326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 1.2787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ee00087e3c4e57bf37a64241fab5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.9588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948c5ce8f82b4a759cbf88224a520693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.7798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdffcfb901b441219cf49ff822c411c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.6637\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    student_model_KD = kd_training(epochs, train_data_loader, teacher_model, student_model_KD, device)\n",
    "    torch.save(student_model_KD, \"model/student_model_KD.pt\")\n",
    "else:\n",
    "    student_model_KD = torch.load(\"model/student_model_KD.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, data_loader, device, testing_mode=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if not testing_mode:\n",
    "        return correct / total\n",
    "        # print(f'Accuracy of {model_name} on the 10000 test images: {100 * correct / total:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_acc = evaluate_model(teacher_model, \"teacher model\", test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_noKD_acc = evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_KD_acc = evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬──────────┬─────────────────────────┐\n",
      "│         Model         │ Accuracy │ % Decrease from Teacher │\n",
      "├───────────────────────┼──────────┼─────────────────────────┤\n",
      "│     Teacher Model     │ 91.54 %  │            -            │\n",
      "│ Student Model (No KD) │ 81.48 %  │          10.99%         │\n",
      "│   Student Model (KD)  │ 79.52 %  │          13.13%         │\n",
      "└───────────────────────┴──────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_acc_percent = teacher_acc * 100\n",
    "student_noKD_acc_percent = student_noKD_acc * 100\n",
    "student_KD_acc_percent = student_KD_acc * 100\n",
    "\n",
    "teacher_to_student_noKD_acc = ((teacher_acc - student_noKD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "acc_table = PrettyTable()\n",
    "acc_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "acc_table.field_names = [\"Model\", \"Accuracy\", \"% Decrease from Teacher\"]\n",
    "acc_table.add_row([\"Teacher Model\", f\"{teacher_acc_percent:.2f} %\", \"-\"])\n",
    "acc_table.add_row([\"Student Model (No KD)\", f\"{student_noKD_acc_percent:.2f} %\", f\"{teacher_to_student_noKD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model (KD)\", f\"{student_KD_acc_percent:.2f} %\", f\"{teacher_to_student_KD_acc:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Speed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_teacher = timeit.timeit(lambda: evaluate_model(teacher_model, \"teacher model\", test_data_loader, device, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_noKD = timeit.timeit(lambda: evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, device, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_KD = timeit.timeit(lambda: evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, device, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬──────────────────────────┬─────────────────────────────────────┬─────────────────────────┐\n",
      "│         Model         │ Device Used to Inference │ Time Averaged over 5 runs (seconds) │ % Decrease from Teacher │\n",
      "├───────────────────────┼──────────────────────────┼─────────────────────────────────────┼─────────────────────────┤\n",
      "│     Teacher Model     │           cuda           │                17.30                │            -            │\n",
      "│ Student Model (No KD) │           cuda           │                12.03                │          30.45%         │\n",
      "│   Student Model (KD)  │           cuda           │                11.84                │          31.58%         │\n",
      "└───────────────────────┴──────────────────────────┴─────────────────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_to_student_noKD_time = ((time_teacher - time_student_noKD) / time_teacher) * 100\n",
    "teacher_to_student_KD_time = ((time_teacher - time_student_KD) / time_teacher) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "speed_table = PrettyTable()\n",
    "speed_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "speed_table.field_names = [\"Model\", \"Device Used to Inference\",f\"Time Averaged over {num_runs} runs (seconds)\", \"% Decrease from Teacher\"]\n",
    "speed_table.add_row([\"Teacher Model\", f\"{device}\", f\"{time_teacher:.2f}\", \"-\"])\n",
    "speed_table.add_row([\"Student Model (No KD)\", f\"{device}\", f\"{time_student_noKD:.2f}\", f\"{teacher_to_student_noKD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model (KD)\", f\"{device}\", f\"{time_student_KD:.2f}\", f\"{teacher_to_student_KD_time:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(speed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬─────────────────┬─────────────────────────┐\n",
      "│     Model     │ Model Size (MB) │ % Decrease from Teacher │\n",
      "├───────────────┼─────────────────┼─────────────────────────┤\n",
      "│ Teacher Model │      94.42      │            -            │\n",
      "│ Student Model │      34.43      │          63.54%         │\n",
      "└───────────────┴─────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_model_size = os.path.getsize(\"model/teacher_model.pt\") / 1e6\n",
    "student_model_size = os.path.getsize(\"model/student_model_KD.pt\") / 1e6\n",
    "teacher_to_student_model_size = (teacher_model_size - student_model_size) * 100 / teacher_model_size\n",
    "\n",
    "# Create a PrettyTable object\n",
    "size_table = PrettyTable()\n",
    "size_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "size_table.field_names = [\"Model\", f\"Model Size (MB)\", \"% Decrease from Teacher\"]\n",
    "size_table.add_row([\"Teacher Model\", f\"{teacher_model_size:.2f}\", \"-\"])\n",
    "size_table.add_row([\"Student Model\", f\"{student_model_size:.2f}\", f\"{teacher_to_student_model_size:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(size_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge distilled smaller model is faster than all the models and more accurate than the non knowledge distilled smaller model that was trained regularly using the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing and Exporting KD Model into CoreML model for iOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Pytorch docs for setup from: https://pytorch.org/executorch/stable/getting-started-setup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization Docs: https://pytorch.org/docs/stable/quantization.html#introduction-to-quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use post training static quantization. There more information of different types of quantization are provided in the quantization docs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantization isn't implemented on accelerators so move model back to cpu\n",
    "student_model_KD.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_KD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach a global qconfig, which contains information about what kind\n",
    "# of observers to attach. Use 'x86' for server inference and 'qnnpack'\n",
    "# for mobile inference. Other quantization configurations such as selecting\n",
    "# symmetric or asymmetric quantization and MinMax or L2Norm calibration techniques\n",
    "# can be specified here.\n",
    "# Note: the old 'fbgemm' is still available but 'x86' is the recommended default\n",
    "# for server inference.\n",
    "# model_fp32.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "student_model_KD.qconfig = torch.ao.quantization.get_default_qconfig('qnnpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse the activations to preceding layers, where applicable.\n",
    "# This needs to be done manually depending on the model architecture.\n",
    "# Common fusions include `conv + relu` and `conv + batchnorm + relu`\n",
    "\n",
    "\n",
    "student_model_KD.fuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model for static quantization. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "student_model_KD_prepared = prepare(student_model_KD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9045, -5.2140,  8.1512,  ...,  0.6184, -7.5581, -6.7732],\n",
       "        [ 0.2097, -0.5478, -0.6438,  ..., -1.9020,  4.2421,  1.0666],\n",
       "        [-1.3402, -2.6020, -1.0782,  ...,  7.8830, -6.7731, -1.8847],\n",
       "        ...,\n",
       "        [-2.3094,  0.1090, -1.6155,  ..., -0.8033,  6.4592,  1.9575],\n",
       "        [-0.3723, -2.5905,  6.9381,  ..., -0.0864, -4.5705, -3.2343],\n",
       "        [-1.9080, -4.6769,  0.3429,  ...,  2.1917, -3.9816, -4.1223]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a batch of images for calibration\n",
    "input, _ = next(iter(train_data_loader))\n",
    "\n",
    "# Run the calibration with real data\n",
    "student_model_KD_prepared(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, and replaces key operators with quantized\n",
    "# implementations.\n",
    "student_model_KD_int8 = convert(student_model_KD_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_276089/860864926.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student_model_KD_int8.load_state_dict(torch.load(\"model/student_model_KD_int8_state_dict.pt\"))\n",
      "/home/bbae/miniconda3/envs/edge/lib/python3.11/site-packages/torch/_utils.py:392: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/69426\n",
    "# Can't load regular model saving method so only save weights to load\n",
    "torch.save(student_model_KD_int8, \"model/student_model_KD_int8.pt\") # save full model just to compare model size\n",
    "torch.save(student_model_KD_int8.state_dict(), \"model/student_model_KD_int8_state_dict.pt\") # use state_dict for actual model loading\n",
    "student_model_KD_int8.load_state_dict(torch.load(\"model/student_model_KD_int8_state_dict.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much size we saved from our previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────┬─────────────────┬─────────────────────────┐\n",
      "│          Model          │ Model Size (MB) │ % Decrease from Teacher │\n",
      "├─────────────────────────┼─────────────────┼─────────────────────────┤\n",
      "│      Teacher Model      │      94.42      │            -            │\n",
      "│      Student Model      │      34.43      │          63.54%         │\n",
      "│ Quantized Student Model │       8.64      │          90.85%         │\n",
      "└─────────────────────────┴─────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_model_size = os.path.getsize(\"model/teacher_model.pt\") / 1e6\n",
    "student_model_size = os.path.getsize(\"model/student_model_KD.pt\") / 1e6\n",
    "student_model_quantized_size = os.path.getsize(\"model/student_model_KD_int8.pt\") / 1e6\n",
    "\n",
    "teacher_to_student_model_size = (teacher_model_size - student_model_size) * 100 / teacher_model_size\n",
    "teacher_to_quantized_student_model_size = (teacher_model_size - student_model_quantized_size) * 100 / teacher_model_size\n",
    "\n",
    "# Create a PrettyTable object\n",
    "size_table = PrettyTable()\n",
    "size_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "size_table.field_names = [\"Model\", f\"Model Size (MB)\", \"% Decrease from Teacher\"]\n",
    "size_table.add_row([\"Teacher Model\", f\"{teacher_model_size:.2f}\", \"-\"])\n",
    "size_table.add_row([\"Student Model\", f\"{student_model_size:.2f}\", f\"{teacher_to_student_model_size:.2f}%\"])\n",
    "size_table.add_row([\"Quantized Student Model\", f\"{student_model_quantized_size:.2f}\", f\"{teacher_to_quantized_student_model_size:.2f}%\"])\n",
    "\n",
    "\n",
    "# Print the table\n",
    "print(size_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see almost a 90% reduction in model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_KD_quant_acc = evaluate_model(student_model_KD_int8, \"quantized student model\", test_data_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────────────┬──────────┬─────────────────────────┐\n",
      "│               Model               │ Accuracy │ % Decrease from Teacher │\n",
      "├───────────────────────────────────┼──────────┼─────────────────────────┤\n",
      "│           Teacher Model           │ 91.54 %  │            -            │\n",
      "│       Student Model (No KD)       │ 81.48 %  │          10.99%         │\n",
      "│         Student Model (KD)        │ 79.52 %  │          13.13%         │\n",
      "│ Student Model Quantized Int8 (KD) │ 79.52 %  │          13.13%         │\n",
      "└───────────────────────────────────┴──────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_acc_percent = teacher_acc * 100\n",
    "student_noKD_acc_percent = student_noKD_acc * 100\n",
    "student_KD_acc_percent = student_KD_acc * 100\n",
    "student_KD_quant_acc_percent = student_KD_quant_acc * 100\n",
    "\n",
    "\n",
    "teacher_to_student_noKD_acc = ((teacher_acc - student_noKD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_quant_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "acc_table = PrettyTable()\n",
    "acc_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "acc_table.field_names = [\"Model\", \"Accuracy\", \"% Decrease from Teacher\"]\n",
    "acc_table.add_row([\"Teacher Model\", f\"{teacher_acc_percent:.2f} %\", \"-\"])\n",
    "acc_table.add_row([\"Student Model (No KD)\", f\"{student_noKD_acc_percent:.2f} %\", f\"{teacher_to_student_noKD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model (KD)\", f\"{student_KD_acc_percent:.2f} %\", f\"{teacher_to_student_KD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model Quantized Int8 (KD)\", f\"{student_KD_quant_acc_percent:.2f} %\", f\"{teacher_to_student_KD_quant_acc:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_teacher_cpu = timeit.timeit(lambda: evaluate_model(teacher_model, \"teacher model\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_noKD_cpu = timeit.timeit(lambda: evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_KD_cpu = timeit.timeit(lambda: evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, 'cpu', testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_quantized = timeit.timeit(lambda: evaluate_model(student_model_KD_int8, \"quantized student model\", test_data_loader,\"cpu\", testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────┬──────────────────────────┬─────────────────────────────────────┬─────────────────────────┐\n",
      "│            Model             │ Device used to inference │ Time Averaged over 5 runs (seconds) │ % Decrease from Teacher │\n",
      "├──────────────────────────────┼──────────────────────────┼─────────────────────────────────────┼─────────────────────────┤\n",
      "│        Teacher Model         │           CPU            │                447.45               │            -            │\n",
      "│    Student Model (No KD)     │           CPU            │                337.30               │          24.62%         │\n",
      "│      Student Model (KD)      │           CPU            │                299.86               │          32.98%         │\n",
      "│ Student Model Quantized (KD) │           CPU            │                320.57               │          28.36%         │\n",
      "└──────────────────────────────┴──────────────────────────┴─────────────────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_to_student_noKD_time = ((time_teacher_cpu - time_student_noKD_cpu) / time_teacher_cpu) * 100\n",
    "teacher_to_student_KD_time = ((time_teacher_cpu - time_student_KD_cpu) / time_teacher_cpu) * 100\n",
    "teacher_to_student_quantized_time = ((time_teacher_cpu - time_student_quantized) / time_teacher_cpu) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "speed_table = PrettyTable()\n",
    "speed_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "speed_table.field_names = [\"Model\", \"Device used to inference\", f\"Time Averaged over {num_runs} runs (seconds)\", \"% Decrease from Teacher\"]\n",
    "speed_table.add_row([\"Teacher Model\", \"CPU\", f\"{time_teacher_cpu:.2f}\", \"-\"])\n",
    "speed_table.add_row([\"Student Model (No KD)\", \"CPU\", f\"{time_student_noKD_cpu:.2f}\", f\"{teacher_to_student_noKD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model (KD)\", \"CPU\", f\"{time_student_KD_cpu:.2f}\", f\"{teacher_to_student_KD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model Quantized (KD)\", \"CPU\", f\"{time_student_quantized:.2f}\", f\"{teacher_to_student_quantized_time:.2f}%\"])\n",
    "\n",
    "\n",
    "# Print the table\n",
    "print(speed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Quantized model is slightly slower than the Original Student model with KD but this might be due to hardware differences as the quantized model is optimized for edge and mobile devices and the original model being optimized for CPU/GPU hardware and this test was done on an x86 CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting as CoreML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantized model doesn't export with CoreML so we have to use the regular KD student model as export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch version 2.5.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.4.0 is the most recent version that has been tested.\n",
      "Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the model with random data.\n",
    "example_input = torch.rand(1, 3, 32, 32) \n",
    "traced_model = torch.jit.trace(student_model_KD, example_input)\n",
    "out = traced_model(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 298/299 [00:00<00:00, 5692.50 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 313.05 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 88/88 [00:00<00:00, 164.47 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 427.90 passes/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input tensor that matches the input shape expected by your model\n",
    "dummy_input = torch.randn(1, 3, 32, 32)  # Adjust based on your input size (e.g., CIFAR-10 images)\n",
    "\n",
    "# Convert the quantized PyTorch model to Core ML directly\n",
    "core_ml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)],\n",
    "    minimum_deployment_target=ct.target.iOS17\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_ml_model.save(\"core_ml_model.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
