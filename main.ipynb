{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import scipy\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torchinfo import summary\n",
    "import timeit\n",
    "import os\n",
    "from prettytable import PrettyTable, SINGLE_BORDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate model compression techniques and export an iOS compatible coreML model to load into mobile devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Define the directory for the dataset\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "testing_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader  = torch.utils.data.DataLoader(training_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "test_data_loader  = torch.utils.data.DataLoader(testing_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet50 (Modified for CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50SmallPretrained(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet50SmallPretrained, self).__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Method 1: Modify first convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Copy weights from pretrained model with adaptation\n",
    "        with torch.no_grad():\n",
    "            # Adapt the weights by averaging over the original kernel size\n",
    "            original_weights = resnet.conv1.weight\n",
    "            new_weights = torch.mean(original_weights.view(64, 3, 7*7), dim=2).view(64, 3, 1, 1)\n",
    "            self.conv1.weight = nn.Parameter(new_weights)\n",
    "        \n",
    "        # Remove the original first maxpool layer as it's too aggressive for small images\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        \n",
    "        # Keep the rest of the architecture\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        # Adjust the final layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # No maxpool\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = ResNet50SmallPretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet50SmallPretrained                  [128, 10]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 34, 34]         192\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 34, 34]         128\n",
       "├─ReLU: 1-3                              [128, 64, 34, 34]         --\n",
       "├─Sequential: 1-4                        [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 34, 34]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 34, 34]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 34, 34]        16,896\n",
       "│    │    └─ReLU: 3-10                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-11                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-13                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-14                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-16                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-17                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-19                   [128, 256, 34, 34]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-20                 [128, 64, 34, 34]         16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-22                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-23                 [128, 64, 34, 34]         36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 64, 34, 34]         128\n",
       "│    │    └─ReLU: 3-25                   [128, 64, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-26                 [128, 256, 34, 34]        16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 256, 34, 34]        512\n",
       "│    │    └─ReLU: 3-28                   [128, 256, 34, 34]        --\n",
       "├─Sequential: 1-5                        [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 34, 34]        32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 34, 34]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 34, 34]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 512, 17, 17]        1,024\n",
       "│    │    └─Sequential: 3-37             [128, 512, 17, 17]        132,096\n",
       "│    │    └─ReLU: 3-38                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-39                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-41                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-42                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-44                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-45                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-47                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-50                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-53                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-56                   [128, 512, 17, 17]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 128, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-59                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 128, 17, 17]        147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 128, 17, 17]        256\n",
       "│    │    └─ReLU: 3-62                   [128, 128, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 512, 17, 17]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 512, 17, 17]        1,024\n",
       "│    │    └─ReLU: 3-65                   [128, 512, 17, 17]        --\n",
       "├─Sequential: 1-6                        [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 17, 17]        131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 17, 17]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 17, 17]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-72                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─Sequential: 3-74             [128, 1024, 9, 9]         526,336\n",
       "│    │    └─ReLU: 3-75                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-81                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-82                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-84                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-85                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-87                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-90                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-102                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-103                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-105                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-106                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-108                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-109                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-111                  [128, 1024, 9, 9]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 9, 9]         --\n",
       "│    │    └─Conv2d: 3-112                [128, 256, 9, 9]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-114                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-115                [128, 256, 9, 9]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [128, 256, 9, 9]          512\n",
       "│    │    └─ReLU: 3-117                  [128, 256, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-118                [128, 1024, 9, 9]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [128, 1024, 9, 9]         2,048\n",
       "│    │    └─ReLU: 3-120                  [128, 1024, 9, 9]         --\n",
       "├─Sequential: 1-7                        [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-14                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-121                [128, 512, 9, 9]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122           [128, 512, 9, 9]          1,024\n",
       "│    │    └─ReLU: 3-123                  [128, 512, 9, 9]          --\n",
       "│    │    └─Conv2d: 3-124                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-126                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-127                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─Sequential: 3-129            [128, 2048, 5, 5]         2,101,248\n",
       "│    │    └─ReLU: 3-130                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-15                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-131                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-133                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-134                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-136                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-137                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-139                  [128, 2048, 5, 5]         --\n",
       "│    └─Bottleneck: 2-16                  [128, 2048, 5, 5]         --\n",
       "│    │    └─Conv2d: 3-140                [128, 512, 5, 5]          1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-142                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-143                [128, 512, 5, 5]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144           [128, 512, 5, 5]          1,024\n",
       "│    │    └─ReLU: 3-145                  [128, 512, 5, 5]          --\n",
       "│    │    └─Conv2d: 3-146                [128, 2048, 5, 5]         1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147           [128, 2048, 5, 5]         4,096\n",
       "│    │    └─ReLU: 3-148                  [128, 2048, 5, 5]         --\n",
       "├─AdaptiveAvgPool2d: 1-8                 [128, 2048, 1, 1]         --\n",
       "├─Linear: 1-9                            [128, 10]                 20,490\n",
       "==========================================================================================\n",
       "Total params: 23,519,306\n",
       "Trainable params: 23,519,306\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 208.49\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 8276.68\n",
       "Params size (MB): 94.08\n",
       "Estimated Total Size (MB): 8372.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(teacher_model, input_size=(batch_size, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(teacher_model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(teacher_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7b2ff41d6e45748e8360849ca2f49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.4998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7296a352b425401fad7429f94901e5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.2772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8e9eda5a7247a993c2dea36883b1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.2187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389e771afc4b4d79b8e88318acf625e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.1884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efad732ea5734080bf10463b88199de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.1665\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_data_loader), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # send to cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = teacher_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # if i % 1000 == 999:    # print every 100 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_data_loader)\n",
    "    # Print average loss for the epoch\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Smaller(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet50Smaller, self).__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        resnet = resnet50()\n",
    "        \n",
    "        # Method 1: Modify first convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        \n",
    "        # Remove the original first maxpool layer as it's too aggressive for small images\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        \n",
    "        # Keep the rest of the architecture\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        # Cut layer 4 from original resnet50\n",
    "        # self.layer4 = resnet.layer4\n",
    "        \n",
    "        # Adjust the final layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # No maxpool\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Student Models\n",
    "# One instance without Knowledge Distillation\n",
    "# One instance for Knowledge Distillation\n",
    "# For comparison of effectiveness of KD\n",
    "student_model_noKD = ResNet50Smaller().to(device)\n",
    "student_model_KD = ResNet50Smaller().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet50Smaller                          [128, 10]                 --\n",
       "├─Conv2d: 1-1                            [128, 64, 32, 32]         1,728\n",
       "├─BatchNorm2d: 1-2                       [128, 64, 32, 32]         128\n",
       "├─ReLU: 1-3                              [128, 64, 32, 32]         --\n",
       "├─Sequential: 1-4                        [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-1                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         4,096\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-3                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-4                  [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-6                    [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-7                  [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-8             [128, 256, 32, 32]        512\n",
       "│    │    └─Sequential: 3-9              [128, 256, 32, 32]        16,896\n",
       "│    │    └─ReLU: 3-10                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-2                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-11                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-13                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-14                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-15            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-16                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-17                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-18            [128, 256, 32, 32]        512\n",
       "│    │    └─ReLU: 3-19                   [128, 256, 32, 32]        --\n",
       "│    └─Bottleneck: 2-3                   [128, 256, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-20                 [128, 64, 32, 32]         16,384\n",
       "│    │    └─BatchNorm2d: 3-21            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-22                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-23                 [128, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [128, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-25                   [128, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-26                 [128, 256, 32, 32]        16,384\n",
       "│    │    └─BatchNorm2d: 3-27            [128, 256, 32, 32]        512\n",
       "│    │    └─ReLU: 3-28                   [128, 256, 32, 32]        --\n",
       "├─Sequential: 1-5                        [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-4                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 32, 32]        32,768\n",
       "│    │    └─BatchNorm2d: 3-30            [128, 128, 32, 32]        256\n",
       "│    │    └─ReLU: 3-31                   [128, 128, 32, 32]        --\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-35                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-36            [128, 512, 16, 16]        1,024\n",
       "│    │    └─Sequential: 3-37             [128, 512, 16, 16]        132,096\n",
       "│    │    └─ReLU: 3-38                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-5                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-39                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-40            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-41                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-42                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-43            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-44                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-45                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-46            [128, 512, 16, 16]        1,024\n",
       "│    │    └─ReLU: 3-47                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-6                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-48                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-49            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-50                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-51                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-52            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-53                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-54                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 512, 16, 16]        1,024\n",
       "│    │    └─ReLU: 3-56                   [128, 512, 16, 16]        --\n",
       "│    └─Bottleneck: 2-7                   [128, 512, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-57                 [128, 128, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-58            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-59                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-60                 [128, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [128, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-62                   [128, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-63                 [128, 512, 16, 16]        65,536\n",
       "│    │    └─BatchNorm2d: 3-64            [128, 512, 16, 16]        1,024\n",
       "│    │    └─ReLU: 3-65                   [128, 512, 16, 16]        --\n",
       "├─Sequential: 1-6                        [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-8                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-66                 [128, 256, 16, 16]        131,072\n",
       "│    │    └─BatchNorm2d: 3-67            [128, 256, 16, 16]        512\n",
       "│    │    └─ReLU: 3-68                   [128, 256, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-69                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-71                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-72                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─Sequential: 3-74             [128, 1024, 8, 8]         526,336\n",
       "│    │    └─ReLU: 3-75                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-9                   [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-76                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-78                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-79                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-81                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-82                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─ReLU: 3-84                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-10                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-85                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-87                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-88                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-90                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-91                 [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92            [128, 1024, 8, 8]         2,048\n",
       "│    │    └─ReLU: 3-93                   [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-11                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-94                 [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-96                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-97                 [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98            [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-99                   [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-100                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─ReLU: 3-102                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-12                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-103                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-105                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-106                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-108                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-109                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─ReLU: 3-111                  [128, 1024, 8, 8]         --\n",
       "│    └─Bottleneck: 2-13                  [128, 1024, 8, 8]         --\n",
       "│    │    └─Conv2d: 3-112                [128, 256, 8, 8]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-114                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-115                [128, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116           [128, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-117                  [128, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-118                [128, 1024, 8, 8]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119           [128, 1024, 8, 8]         2,048\n",
       "│    │    └─ReLU: 3-120                  [128, 1024, 8, 8]         --\n",
       "├─AdaptiveAvgPool2d: 1-7                 [128, 1024, 1, 1]         --\n",
       "├─Linear: 1-8                            [128, 10]                 10,250\n",
       "==========================================================================================\n",
       "Total params: 8,545,866\n",
       "Trainable params: 8,545,866\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 132.30\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 6610.23\n",
       "Params size (MB): 34.18\n",
       "Estimated Total Size (MB): 6645.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(student_model_noKD, input_size=(batch_size, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Student Training (on Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(student_model_noKD.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(student_model_noKD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2677c01197d4f7cafdca086e932f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 1.4047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6145e0953243a4840954d3a71f5a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 0.9068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdd18cd5aa447888e6bde831de149c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.7048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57461415011a4625ae142ec6ffef07ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.5997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becdf5f8b37741acb9f750a312143163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.5245\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_data_loader), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # send to cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = student_model_noKD(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_data_loader)\n",
    "    # Print average loss for the epoch\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Training from Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code taken from: https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(student_model_KD.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(student_model_KD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353aaed56a4349c49d339ba14e5dbcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 2.0814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5aa6ff4edb4628b44f2e2ae7154aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Average Loss: 1.2638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8c4e394f2a46a58eb65f571c267dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Average Loss: 0.9330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d1e82f994b40998366d81b3e94c423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Average Loss: 0.7500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5117c8385c7b49ea9b04059a5df5c256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Average Loss: 0.6369\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Set teacher model to evaluation mode to not mess with gradients of teacher model\n",
    "teacher = teacher_model.eval()\n",
    "\n",
    "student_model_KD.train() # Student to train mode\n",
    "\n",
    "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "temperature = 2\n",
    "soft_target_loss_weight = 0.25\n",
    "ce_loss_weight = 0.75\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_data_loader), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # send to cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        student_logits = student_model_KD(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "        \n",
    "        #Soften the student logits by applying softmax first and log() second\n",
    "        soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "        soft_prob = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "\n",
    "        # Calculate the soft targets loss. Scaled by temperature**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "        soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (temperature**2)\n",
    "\n",
    "        # Calculate the true label loss\n",
    "        label_loss = criterion(student_logits, labels)\n",
    "\n",
    "        # Weighted sum of the two losses\n",
    "        loss = (soft_target_loss_weight * soft_targets_loss) + (ce_loss_weight * label_loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_data_loader)\n",
    "    # Print average loss for the epoch\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, data_loader, testing_mode=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if not testing_mode:\n",
    "        return correct / total\n",
    "        # print(f'Accuracy of {model_name} on the 10000 test images: {100 * correct / total:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_acc = evaluate_model(teacher_model, \"teacher model\", test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_noKD_acc = evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_KD_acc = evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬──────────┬─────────────────────────┐\n",
      "│         Model         │ Accuracy │ % Decrease from Teacher │\n",
      "├───────────────────────┼──────────┼─────────────────────────┤\n",
      "│     Teacher Model     │ 92.03 %  │            -            │\n",
      "│ Student Model (No KD) │ 79.79 %  │          13.30%         │\n",
      "│   Student Model (KD)  │ 82.23 %  │          10.65%         │\n",
      "└───────────────────────┴──────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_acc_percent = teacher_acc * 100\n",
    "student_noKD_acc_percent = student_noKD_acc * 100\n",
    "student_KD_acc_percent = student_KD_acc * 100\n",
    "\n",
    "teacher_to_student_noKD_acc = ((teacher_acc - student_noKD_acc) / teacher_acc) * 100\n",
    "teacher_to_student_KD_acc = ((teacher_acc - student_KD_acc) / teacher_acc) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "acc_table = PrettyTable()\n",
    "acc_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "acc_table.field_names = [\"Model\", \"Accuracy\", \"% Decrease from Teacher\"]\n",
    "acc_table.add_row([\"Teacher Model\", f\"{teacher_acc_percent:.2f} %\", \"-\"])\n",
    "acc_table.add_row([\"Student Model (No KD)\", f\"{student_noKD_acc_percent:.2f} %\", f\"{teacher_to_student_noKD_acc:.2f}%\"])\n",
    "acc_table.add_row([\"Student Model (KD)\", f\"{student_KD_acc_percent:.2f} %\", f\"{teacher_to_student_KD_acc:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Speed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_teacher = timeit.timeit(lambda: evaluate_model(teacher_model, \"teacher model\", test_data_loader, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_noKD = timeit.timeit(lambda: evaluate_model(student_model_noKD, \"student model with no Knowledge Distillation\", test_data_loader, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_student_KD = timeit.timeit(lambda: evaluate_model(student_model_KD, \"student model with Knowledge Distillation\", test_data_loader, testing_mode=True), number=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┬─────────────────────────────────────┬─────────────────────────┐\n",
      "│         Model         │ Time Averaged over 5 runs (seconds) │ % Decrease from Teacher │\n",
      "├───────────────────────┼─────────────────────────────────────┼─────────────────────────┤\n",
      "│     Teacher Model     │                18.63                │            -            │\n",
      "│ Student Model (No KD) │                14.17                │          23.95%         │\n",
      "│   Student Model (KD)  │                13.69                │          26.54%         │\n",
      "└───────────────────────┴─────────────────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "teacher_to_student_noKD_time = ((time_teacher - time_student_noKD) / time_teacher) * 100\n",
    "teacher_to_student_KD_time = ((time_teacher - time_student_KD) / time_teacher) * 100\n",
    "\n",
    "# Create a PrettyTable object\n",
    "speed_table = PrettyTable()\n",
    "speed_table.set_style(SINGLE_BORDER)\n",
    "\n",
    "# Define the columns\n",
    "speed_table.field_names = [\"Model\", f\"Time Averaged over {num_runs} runs (seconds)\", \"% Decrease from Teacher\"]\n",
    "speed_table.add_row([\"Teacher Model\", f\"{time_teacher:.2f}\", \"-\"])\n",
    "speed_table.add_row([\"Student Model (No KD)\", f\"{time_student_noKD:.2f}\", f\"{teacher_to_student_noKD_time:.2f}%\"])\n",
    "speed_table.add_row([\"Student Model (KD)\", f\"{time_student_KD:.2f}\", f\"{teacher_to_student_KD_time:.2f}%\"])\n",
    "\n",
    "# Print the table\n",
    "print(speed_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge distilled smaller model is faster than all the models and more accurate than the non knowledge distilled smaller model that was trained regularly using the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Knowledge Distilled Model into CoreML model for iOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Pytorch docs from: https://pytorch.org/executorch/stable/getting-started-setup.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
